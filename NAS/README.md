# NAS

[APQ: Joint Search for Network Architecture, Pruning and Quantization Policy](https://arxiv.org/pdf/2006.08509.pdf)

- By optimizing the neural architecture, pruning policy, and quantization policy jointly through training a quantization-aware accuracy predictor with full-precision knowledge, APQ is presented for efficient deep learning inference on resource-constrained hardware.

[HAT: Hardware-Aware Transformers for Efficient Natural Language Processing](https://arxiv.org/pdf/2005.14187.pdf)

- By constructing a design space with arbitrary encoder-decoder attention and heterogeneous layers, training a SuperTransformer with weight sharing, and performing evolutionary search with hardware constraints, Hardware-Aware Transformers (HAT) enables low-latency inference on resource-constrained hardware platforms.

[MCUNet: Tiny Deep Learning on IoT Devices](https://arxiv.org/pdf/2007.10319.pdf)

- By jointly designs an efficient neural architecture (TinyNAS) with optimization of the search space and the specialization of the network architecture, and a lightweight inference engine (TinyEngine) with memory scheduling according to the overall network topology, MCUNet reduces the memory usage and accelerates the inference.

[NAAS: Neural Accelerator Architecture Search](https://arxiv.org/pdf/2105.13258.pdf)

- By holistically searching the neural network architecture, accelerator architecture and compiler mapping in one optimization loop, Neural Accelerator Architecture Search (NAAS) composes highly matched architectures together with efficient mapping.

[Neural-Hardware Architecture Search](http://mlforsystems.org/assets/papers/neurips2019/neural_hardware_lin_2019.pdf)

- By using machine learning based design and optimization methodology with evolution strategy based hardware architecture search and one-shot hyper-net based quantized neural architecture search, this paper's design composes highly matched neural-hardware architectures.

[ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware](https://arxiv.org/pdf/1812.00332.pdf)

- By directly learning the architectures for large-scale target tasks and target hardware platforms, ProxylessNAS is able to deal with high memory consumption, reduce the computational cost, and allow a large candidate set.